/*
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    PRINT PARAMS SUMMARY
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
*/

include { paramsSummaryLog; paramsSummaryMap; fromSamplesheet } from 'plugin/nf-validation'

def logo = NfcoreTemplate.logo(workflow, params.monochrome_logs)
def citation = '\n' + WorkflowMain.citation(workflow) + '\n'
def summary_params = paramsSummaryMap(workflow)

// Print parameter summary log to screen
log.info logo + paramsSummaryLog(workflow) + citation

WorkflowRaredisease.initialise(params, log)

/*
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    CHECK MANDATORY PARAMETERS
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
*/

def mandatoryParams = [
    "fasta",
    "input",

]
def missingParamsCount = 0

for (param in mandatoryParams.unique()) {
    if (params[param] == null) {
        println("params." + param + " not set.")
        missingParamsCount += 1
    }
}

if (missingParamsCount>0) {
    error("\nSet missing parameters and restart the run. For more information please check usage documentation on github.")
}

/*
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    IMPORT MODULES AND SUBWORKFLOWS
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
*/

// SUBWORKFLOWS

include { DRAGENA_IDAT2GTC                                   } from '../subworkflows/dragena_idat2gtc'
include { DRAGENA_GTC2VCF                                    } from '../subworkflows/dragena_gtc2vcf'


/*
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    RUN MAIN WORKFLOW
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
*/

// Info required for completion email and summary
def multiqc_report = []

workflow IDAT2VCF {

    ch_versions = Channel.empty()

    // Initialize read, sample, and case_info channels
    ch_input = Channel.fromPath(params.input)
    Channel.fromSamplesheet("input")
        .tap { ch_original_input }
        .map { meta, idat1, idat2 -> 
            [meta, idat1, idat2]
        }
        .reduce([:]) { counts, entry -> // Get counts of each sample in the samplesheet
            def (meta, idat1, idat2) = entry
            counts[meta.sample] = (counts[meta.sample] ?: 0) + 1
            counts
        }
        .combine(ch_original_input)
        .map { counts, meta, idat1, idat2 ->
            def new_meta = meta
            return [new_meta, [idat1, idat2]]
        }
        .tap { ch_input_counts }
        .map { meta, idats -> idats }
        .reduce([:]) { counts, idats -> // Get line number for each row to construct unique sample ids
            counts[idats] = counts.size() + 1
            return counts
        }
        .combine(ch_input_counts)
        .map { lineno, meta, idats -> // Append line number to sample id
            def new_meta = meta + [id: meta.sample]
            return [new_meta, idats]
        }
        .set { ch_reads }



    // Initialize file channels for PREPARE_REFERENCES subworkflow
    ch_genome_fasta             = Channel.fromPath(params.fasta).map { it -> [[id:it[0].simpleName], it] }.collect()
    ch_genome_fai               = params.fai                        ? Channel.fromPath(params.fai).map {it -> [[id:it[0].simpleName], it]}.collect()
                                                                    : Channel.empty()                                                  
    manifest_bpm                = params.manifest_bpm               ? Channel.fromPath(params.manifest_bpm).collect()
                                                                    : Channel.value([])
    manifest_csv                = params.manifest_csv               ? Channel.fromPath(params.manifest_csv).collect()
                                                                    : Channel.value([]) 
    clusterfile                 = params.clusterfile                ? Channel.fromPath(params.clusterfile).collect()
                                                                    : Channel.value([]) 
    

    //
    // DRAGENA_IDAT2GTC.
    //
    DRAGENA_IDAT2GTC (
        ch_reads,
        manifest_bpm,
        clusterfile,
    )
    ch_versions   = ch_versions.mix(DRAGENA_IDAT2GTC.out.versions)

    DRAGENA_GTC2VCF (
        DRAGENA_IDAT2GTC.out.gtc,
        manifest_bpm,
        manifest_csv,
        ch_genome_fasta,
        ch_genome_fai
    )
    ch_versions   = ch_versions.mix(DRAGENA_GTC2VCF.out.versions)

}
/*
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    COMPLETION EMAIL AND SUMMARY
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
*/

workflow.onComplete {
    if (params.email || params.email_on_fail) {
        NfcoreTemplate.email(workflow, params, summary_params, projectDir, log, multiqc_report)
    }
    NfcoreTemplate.dump_parameters(workflow, params)
    NfcoreTemplate.summary(workflow, params, log)
    if (params.hook_url) {
        NfcoreTemplate.IM_notification(workflow, params, summary_params, projectDir, log)
    }
}

workflow.onError {
    if (workflow.errorReport.contains("Process requirement exceeds available memory")) {
        println("ðŸ›‘ Default resources exceed availability ðŸ›‘ ")
        println("ðŸ’¡ See here on how to configure pipeline: https://nf-co.re/docs/usage/configuration#tuning-workflow-resources ðŸ’¡")
    }
}


/*
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    THE END
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
*/
